{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ETAS: Ridgecrest, 4ish July, 2019\n",
    "\n",
    "Time\n",
    "2019-07-04 17:33:49 (UTC)\n",
    "Location\n",
    "35.705°N 117.506°W\n",
    "Depth\n",
    "10.7 km"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "failed while loading urllib and/or urllib. maybe python 3.x?\n",
      "comcat not available. consider installing comcat for improved catalog operations; see https://github.com/usgs/libcomcat\n"
     ]
    }
   ],
   "source": [
    "import datetime as dtm\n",
    "import matplotlib.dates as mpd\n",
    "import pytz\n",
    "tzutc = pytz.timezone('UTC')\n",
    "\n",
    "#import operator\n",
    "import math\n",
    "import random\n",
    "import numpy\n",
    "import scipy\n",
    "import scipy.optimize as spo\n",
    "from scipy import interpolate\n",
    "import itertools\n",
    "import sys\n",
    "#import scipy.optimize as spo\n",
    "import os\n",
    "import operator\n",
    "#from PIL import Image as ipp\n",
    "import multiprocessing as mpp\n",
    "#\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import json\n",
    "import pickle\n",
    "#\n",
    "\n",
    "import geopy.distance\n",
    "#from geopy.distance import vincenty\n",
    "#from geopy.distance import great_circle\n",
    "#\n",
    "#import shapely.geometry as sgp\n",
    "os.environ['PROJ_LIB'] = '{}/anaconda3/share/proj'.format(os.getenv('HOME'))\n",
    "#\n",
    "from mpl_toolkits.basemap import Basemap as Basemap\n",
    "from matplotlib.backends.backend_agg import FigureCanvasAgg as FigureCanvas\n",
    "from geographiclib.geodesic import Geodesic as ggp\n",
    "#\n",
    "\n",
    "#import ANSStools as atp\n",
    "from yodiipy import ANSStools as atp\n",
    "#\n",
    "import contours2kml\n",
    "import globalETAS as gep\n",
    "\n",
    "#import global_etas_auto as ggep\n",
    "\n",
    "from eq_params import *\n",
    "#\n",
    "from nepal_figs import *\n",
    "import optimizers\n",
    "#\n",
    "import random\n",
    "import geopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "to_dt = dtm.datetime.now(pytz.timezone('UTC'))\n",
    "#to_dt = dtm.datetime(2019,7,5,0,0,0, tzinfo=pytz.timezone('UTC'))\n",
    "#\n",
    "Lr_factor = 10.\n",
    "# define these from the t_now in the actual etas object, in the event that we load it from pickle,\n",
    "#  rather than calc it here.\n",
    "#f_path = '/home/myoder/Dropbox/Research/etas/italy_2016_10/etas_{}'.format(to_dt)\n",
    "#f_root = 'etas_2016'\n",
    "#\n",
    "\n",
    "t0 = dtm.datetime.now(pytz.timezone('UTC'))\n",
    "t_ms = t0\n",
    "n_cpu=None\n",
    "#\n",
    "lat0 = 35.705\n",
    "lon0 = -117.506\n",
    "#\n",
    "#ll_sacramento = (lon0, lat0)\n",
    "\n",
    "#m0 = 7.8\n",
    "\n",
    "d_lat=2.\n",
    "d_lon=2.\n",
    "#\n",
    "lats = [lat0-d_lat, lat0+d_lat]\n",
    "lons = [lon0-d_lon, lon0+d_lon]\n",
    "#to_dt = t0-dtm.timedelta(hours=2)\n",
    "#to_dt = dtm.datetime.now(pytz.utc)\n",
    "#\n",
    "#etas = ggep.auto_etas(to_dt=to_dt, Lr_factor=Lr_factor, dt_0=5)\n",
    "#italy_prams = {'do_recarray': True, 'D_fract': 1.5,\n",
    "#                't_0':dtm.datetime(1990, 1, 1, 0, 0, tzinfo=pytz.timezone('UTC')),\n",
    "#                't_now':to_dt, \n",
    "#                'lats': [42.,43.5], 'p': 1.1, 'b1': 1.0, 'mc': 2.5, 'q': 1.5,\n",
    "#                'lons': [12.,15.], 'dmstar': 1.0, 'b2': 1.5, 'd_tau': 2.28,\n",
    "#                'incat': None, 'fit_factor': 2.0, 'd_lambda': 1.76}\n",
    "eq_prams = {'do_recarray': True, 'D_fract': 1.5,\n",
    "               't_0':dtm.datetime(1990, 1, 1, 0, 0, tzinfo=pytz.timezone('UTC')),\n",
    "               't_now':to_dt, 't_future':None ,\n",
    "               'lats': lats, 'p_cat': 1.1, 'b1': 1.0, 'mc': 3.0, 'q_cat': 1.5,\n",
    "               'p_etas':1.1, 'q_etas':1.5,\n",
    "               'lons': lons, 'dmstar': 1.0, 'b2': 1.5, 'd_tau': 2.28,\n",
    "               'incat': None, 'fit_factor': 2.0, 'd_lambda': 1.76, 'etas_range_padding':1.5,\n",
    "            'etas_range_factor':30.0, 'ab_ratio_expon':.25 }\n",
    "#eq_prams.update({'mc':3.0, 'd_lat':.25, 'd_lon':.25})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "etas_prams:  {'incat': None, 'lats': [32.0, 38.0], 'lons': [-117.0, -114.0], 'mc': 2.5, 'date_range': ['1990-1-1', None], 'D_fract': 1.5, 'd_lambda': 1.76, 'd_tau': 2.28, 'fit_factor': 1.5, 'p': 1.1, 'q': 1.5, 'dmstar': 1.0, 'b1': 1.0, 'b2': 1.5, 'do_recarray': False}\n",
      "results fetched.\n"
     ]
    }
   ],
   "source": [
    "# let's add a preliminary map...\n",
    "class Preliminary_Map(object):\n",
    "    def __init__(self, lats, lons):\n",
    "        pass\n",
    "#\n",
    "# comcat may not be working (overloaded, probably after the earthquake):\n",
    "# try anss:\n",
    "mycat = None\n",
    "#\n",
    "# we've added a new web-api based comcat catalog, and wrapped it around the old catfromANSS(), or we can use\n",
    "#. the new names.\n",
    "# mycat = atp.cat_from_comcat(lon=lons, lat=lats, minMag=2.5,\n",
    "# mycat = atp.catfromANSS(lon=lons, lat=lats, minMag=2.5,\n",
    "mycat = atp.cat_from_anss_comcat(lon=lons, lat=lats, minMag=eq_prams['mc'],\n",
    "                        dates0=[dtm.datetime(2005,1,1, tzinfo=pytz.timezone('UTC')), \n",
    "                                dtm.datetime.now(pytz.timezone('UTC'))],\n",
    "                            Nmax=None, fout=None, rec_array=True)\n",
    "#                        dates0=[dtm.datetime(2005,1,1, tzinfo=tzutc), None], Nmax=None, fout=None, rec_array=True)\n",
    "\n",
    "mycat = gep.make_ETAS_catalog_mpp(incat=mycat, n_cpu=n_cpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#eq_prams['t_now'] = dtm.datetime(2019,7,6,18,0,0, tzinfo=pytz.timezone('UTC'))\n",
    "eq_prams['t_now'] = dtm.datetime.now(pytz.timezone('UTC'))\n",
    "#eq_prams['mc'] = 3.5\n",
    "# eq_prams['lats'] = [lat0 - 1., lat0 + 1.]\n",
    "# eq_prams['lons'] = [lon0 - 1., lon0 + 1.]\n",
    "#\n",
    "# eq_prams['lats'] = [lat0 - 2., lat0 + 2.]\n",
    "# eq_prams['lons'] = [lon0 - 2., lon0 + 2.]\n",
    "#\n",
    "n_cpu = 2*mpp.cpu_count()\n",
    "#n_cpu = 6\n",
    "#n_cpu=5\n",
    "etas = gep.ETAS_mpp(n_cpu=n_cpu, catalog=mycat, **eq_prams)\n",
    "#\n",
    "# we've run this; we can reload it from pickle:\n",
    "#with open('data/etas_201610.pkl', 'rb') as fin:\n",
    "#    etas = pickle.load(fin)\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "event_name = 'Ridgecrest_July_2019'\n",
    "#f_path = '/home/myoder/Dropbox/Research/etas/{}/etas_{}'.format(event_name, etas.t_now)\n",
    "#f_path = '{}/data_export/Research/etas/{}/etas_{}'.format(os.getenv('HOME'), event_name, etas.t_now)\n",
    "f_path = '{}/Dropbox/Research/etas/{}/etas_{}'.format(os.getenv('HOME'), event_name, etas.t_now)\n",
    "f_root = 'etas_{}_2019_07'.format(event_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print( etas.t_now, etas.t_forecast, etas.catalog[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fg=plt.figure(0, figsize=(12,10))\n",
    "ax=plt.gca()\n",
    "# lats_map= , lons_map=\n",
    "etas.make_etas_contour_map(n_contours=25, fignum=0, map_resolution='f', alpha=.3, ax=ax)\n",
    "#\n",
    "#mainshock = sorted(etas.catalog, key=lambda rw: rw['mag'])[-1]\n",
    "#print('mainshock: ', mainshock)\n",
    "# get mainshock. it's an m>6 event in the last week or so... this is subjective.\n",
    "# if we just look for the biggest event, we get the L'Aquila event, so we'll need to be more creative...\n",
    "# or just specify it.\n",
    "\n",
    "mainshock = etas.catalog[-1]\n",
    "for j,eq in enumerate(reversed(etas.catalog)):\n",
    "    #print('*** ', pytz.utc.localize(eq['event_date'].astype(dtm.datetime)))\n",
    "    if pytz.utc.localize(eq['event_date'].astype(dtm.datetime))<etas.t_now-dtm.timedelta(days=180): break\n",
    "    if eq['mag']>mainshock['mag']:\n",
    "        mainshock = eq\n",
    "        #\n",
    "    #\n",
    "#\n",
    "print('ms: ', mainshock, mainshock['lon'], mainshock['lat'])\n",
    "x,y = etas.cm(mainshock['lon'], mainshock['lat'])\n",
    "#\n",
    "#print('mm: ', max(etas.catalog['mag']))\n",
    "#\n",
    "# let's get everything m>6 in the last 6 months?\n",
    "m6s = [rw for rw in etas.catalog if rw['mag'] >= 6. \n",
    "       and pytz.utc.localize(rw['event_date'].astype(dtm.datetime))>to_dt-dtm.timedelta(days=180)]\n",
    "#\n",
    "# plot mainshock:\n",
    "dt = mainshock['event_date'].astype(dtm.datetime)\n",
    "dt=t0\n",
    "dt_str = '{}-{}-{} {}:{}:{}'.format(dt.year, dt.month, dt.day, dt.hour, dt.minute, dt.second)\n",
    "#etas.cm.plot([x], [y], latlon=False, marker='*', color='r', ms=16, zorder=11,\n",
    "#                   label='m={}, {}'.format(mainshock['mag'], dt_str))\n",
    "#etas.cm.plot([lon0], [lat0], latlon=False, marker='*', color='r', ms=16, zorder=11,\n",
    "#                   label='m={}, {}'.format(m0, dt_str))\n",
    "\n",
    "ax.set_title('ETAS: {}, {}\\n\\n'.format(event_name, etas.t_now), size=16)\n",
    "for j,m6 in enumerate(m6s):\n",
    "    clr = colors_[j%len(colors_)]\n",
    "    #\n",
    "    dt = m6['event_date'].astype(dtm.datetime)\n",
    "    dt_str = '{}-{}-{} {}:{}:{}'.format(dt.year, dt.month, dt.day, dt.hour, dt.minute, dt.second)\n",
    "    etas.cm.scatter(m6['lon'], m6['lat'], s=2*(m6['mag']+2.), edgecolors=clr, \n",
    "                          c='none', marker='o', zorder=11, label='m={}, {}'.format(m6['mag'], dt_str))\n",
    "\n",
    "#x,y = etas.cm(*ll_sacramento)\n",
    "#etas.cm.scatter([x],[y], marker='o', s=18, edgecolors='r', c='r',\n",
    "#                    label='Sacramento')\n",
    "t_cat = mpd.date2num(etas.t_now-dtm.timedelta(days=15))\n",
    "print('tt: ', t_cat, etas.catalog['event_date'][0], type(etas.catalog['event_date'][0]))\n",
    "k=0\n",
    "\n",
    "# for j,rw in enumerate(etas.catalog):\n",
    "#     if mpd.date2num(rw['event_date'].astype(dtm.datetime))<t_cat: continue\n",
    "#     k+=1\n",
    "#     clr = colors_[k%len(colors_)]\n",
    "#     #\n",
    "#     dt = rw['event_date'].astype(dtm.datetime)\n",
    "#     dt_str = '{}-{}-{} {}:{}:{}'.format(dt.year, dt.month, dt.day, dt.hour, dt.minute, dt.second)\n",
    "#     #etas.cm.scatter(rw['lon'],rw['lat'], s=3*(rw['mag']+12.), edgecolors=clr, \n",
    "#     #                      c='none', marker='o', zorder=11, label='m={}, {}'.format(rw['mag'], dt_str))\n",
    "#     etas.cm.plot(rw['lon'],rw['lat'], ms=2.*(rw['mag']+2.), color=clr, \n",
    "#                           marker='o', zorder=11, label='m={}, {}'.format(rw['mag'], dt_str), latlon=True)\n",
    "    \n",
    "    #\n",
    "plt.gca().legend()\n",
    "#print(etas.catalog[-10:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fg2=plt.figure(0, figsize=(12,10))\n",
    "ax=plt.gca()\n",
    "etas.make_etas_contour_map(n_contours=25, fignum=0, map_resolution='f', alpha=.3, ax=ax)\n",
    "#\n",
    "#mainshock = sorted(etas.catalog, key=lambda rw: rw['mag'])[-1]\n",
    "#print('mainshock: ', mainshock)\n",
    "# get mainshock. it's an m>6 event in the last week or so... this is subjective.\n",
    "# if we just look for the biggest event, we get the L'Aquila event, so we'll need to be more creative...\n",
    "# or just specify it.\n",
    "\n",
    "mainshock = etas.catalog[-1]\n",
    "for j,eq in enumerate(reversed(etas.catalog)):\n",
    "    #print('*** ', pytz.utc.localize(eq['event_date'].astype(dtm.datetime)))\n",
    "    if pytz.utc.localize(eq['event_date'].astype(dtm.datetime))<etas.t_now-dtm.timedelta(days=180): break\n",
    "    if eq['mag']>mainshock['mag']:\n",
    "        mainshock = eq\n",
    "        #\n",
    "    #\n",
    "#\n",
    "print('ms: ', mainshock, mainshock['lon'], mainshock['lat'])\n",
    "x,y = etas.cm(mainshock['lon'], mainshock['lat'])\n",
    "#\n",
    "#print('mm: ', max(etas.catalog['mag']))\n",
    "#\n",
    "# let's get everything m>6 in the last 6 months?\n",
    "m6s = [rw for rw in etas.catalog if rw['mag'] >= 6. \n",
    "       and pytz.utc.localize(rw['event_date'].astype(dtm.datetime))>to_dt-dtm.timedelta(days=180)]\n",
    "#\n",
    "# plot mainshock:\n",
    "dt = mainshock['event_date'].astype(dtm.datetime)\n",
    "dt=t0\n",
    "dt_str = '{}-{}-{} {}:{}:{}'.format(dt.year, dt.month, dt.day, dt.hour, dt.minute, dt.second)\n",
    "#etas.cm.plot([x], [y], latlon=False, marker='*', color='r', ms=16, zorder=11,\n",
    "#                   label='m={}, {}'.format(mainshock['mag'], dt_str))\n",
    "#etas.cm.plot([lon0], [lat0], latlon=False, marker='*', color='r', ms=16, zorder=11,\n",
    "#                   label='m={}, {}'.format(m0, dt_str))\n",
    "\n",
    "ax.set_title('ETAS: {}, {}\\n\\n'.format(event_name, etas.t_now), size=16)\n",
    "# for j,m6 in enumerate(m6s):\n",
    "#     clr = colors_[j%len(colors_)]\n",
    "#     #\n",
    "#     dt = m6['event_date'].astype(dtm.datetime)\n",
    "#     dt_str = '{}-{}-{} {}:{}:{}'.format(dt.year, dt.month, dt.day, dt.hour, dt.minute, dt.second)\n",
    "#     etas.cm.scatter(m6['lon'], m6['lat'], s=2*(m6['mag']+2.), edgecolors=clr, \n",
    "#                           c='none', marker='o', zorder=11, label='m={}, {}'.format(m6['mag'], dt_str))\n",
    "\n",
    "# ix = (numpy.array([pytz.utc.localize(x.astype(dtm.datetime)) for x in etas.catalog['event_date']])<=etas.t_now and\n",
    "#       numpy.array([pytz.utc.localize(x.astype(dtm.datetime)) \n",
    "#                    for x in etas.catalog['event_date']])>=dtm.datetime(2019,7,4, tzinfo=pytz.timezone('UTC')))\n",
    "ix = numpy.array([x<=etas.t_now and x>dtm.datetime(2019,7,4, tzinfo=pytz.timezone('UTC'))\n",
    "      for x in [pytz.utc.localize(x.astype(dtm.datetime)) for x in etas.catalog['event_date']]])\n",
    "#\n",
    "etas.cm.plot(etas.catalog['lon'][ix], etas.catalog['lat'][ix], marker='.', ls='')\n",
    "#x,y = etas.cm(*ll_sacramento)\n",
    "#etas.cm.scatter([x],[y], marker='o', s=18, edgecolors='r', c='r',\n",
    "#                    label='Sacramento')\n",
    "t_cat = mpd.date2num(etas.t_now-dtm.timedelta(days=15))\n",
    "print('tt: ', t_cat, etas.catalog['event_date'][0], type(etas.catalog['event_date'][0]))\n",
    "k=0\n",
    "\n",
    "# for j,rw in enumerate(etas.catalog):\n",
    "#     if mpd.date2num(rw['event_date'].astype(dtm.datetime))<t_cat: continue\n",
    "#     k+=1\n",
    "#     clr = colors_[k%len(colors_)]\n",
    "#     #\n",
    "#     dt = rw['event_date'].astype(dtm.datetime)\n",
    "#     dt_str = '{}-{}-{} {}:{}:{}'.format(dt.year, dt.month, dt.day, dt.hour, dt.minute, dt.second)\n",
    "#     #etas.cm.scatter(rw['lon'],rw['lat'], s=3*(rw['mag']+12.), edgecolors=clr, \n",
    "#     #                      c='none', marker='o', zorder=11, label='m={}, {}'.format(rw['mag'], dt_str))\n",
    "#     etas.cm.plot(rw['lon'],rw['lat'], ms=2.*(rw['mag']+2.), color=clr, \n",
    "#                           marker='o', zorder=11, label='m={}, {}'.format(rw['mag'], dt_str), latlon=True)\n",
    "    \n",
    "    #\n",
    "ax.legend(loc=0)\n",
    "#print(etas.catalog[-10:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(['{},{}\\n'.format(rw['event_date'], rw['mag'] ) for rw in etas.catalog if rw['mag'] >= 5.5])\n",
    "len(['{},{}\\n'.format(rw['event_date'], rw['mag'] ) for rw in etas.catalog if rw['mag'] >= 5.5\n",
    "     and rw['event_date'].astype(dtm.datetime)>dtm.datetime(2016,10,20)])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## hey, pickling works with the new ETAS objects (or at least it appears to...):\n",
    "# with open('data/etas_201610.pkl', 'wb') as fpkl:\n",
    "#     pickle.dump( etas, fpkl)    \n",
    "#\n",
    "#with open('data/etas_201610.pkl', 'rb') as fin:\n",
    "#    etas2 = pickle.load(fin)\n",
    "#\n",
    "#print(etas2.catalog[0:5])\n",
    "# TODO: we want the datetime part of the filename to come from the etas object itself, for purposes of\n",
    "# integrity. BUT, we want this script to be a bit more portable, so we should replace all the etas\n",
    "# references/object name to just 'etas'\n",
    "#\n",
    "etas.export_kml(os.path.join(f_path, '{}_{}.kml'.format(f_root, str(etas.t_now).replace(' ', '_'))))\n",
    "etas.export_xyz(os.path.join(f_path, '{}_{}.xyz'.format(f_root, str(etas.t_now).replace(' ', '_'))))\n",
    "fg.savefig(os.path.join(f_path, '{}_{}.png'.format(f_root, str(etas.t_now).replace(' ', '_'))))\n",
    "fg2.savefig(os.path.join(f_path, '{}_{}_with_equakes.png'.format(f_root, str(etas.t_now).replace(' ', '_'))))\n",
    "\n",
    "\n",
    "#\n",
    "# so this worked, once upon a time, but breaks maybe when the script does not run cleanly all the way through?\n",
    "with open (os.path.join(f_path, '{}_{}.pkl'.format(f_root, str(etas.t_now).replace(' ', '_'))), 'wb') as fpkl:\n",
    "   pickle.dump(etas, fpkl)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,5))\n",
    "plt.clf()\n",
    "ax1=plt.subplot('121')\n",
    "ax2=plt.subplot('122')\n",
    "ax2.grid()\n",
    "ax1.plot(etas.catalog['lon'], etas.catalog['lat'], ',')\n",
    "ax1.plot([mainshock['lon']], [mainshock['lat']], marker='*', color='r', ms=16, zorder=11)\n",
    "#\n",
    "ax2.plot([m for m in reversed(sorted(etas.catalog['mag']))], numpy.arange(1,len(etas.catalog)+1),\n",
    "         '.-', lw=2.)\n",
    "ax2.set_yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How 'bout some intervals and magnitudes:\n",
    "#\n",
    "# (we should probably build this plot int the class, or really, we should make a separate plotter class, that\n",
    "#  takes and ETAS object as an input.)\n",
    "#\n",
    "fg = plt.figure(figsize=(14,7))\n",
    "ax1 = fg.add_subplot('211')\n",
    "ax2 = fg.add_subplot('212', sharex=ax1)\n",
    "#\n",
    "ax1.grid()\n",
    "ax2.grid()\n",
    "#\n",
    "ax1.set_title('Intervals')\n",
    "ax1.set_ylabel('Mean Interval $\\Delta t / N$')\n",
    "ax2.set_title('Magnitudes')\n",
    "ax2.set_xlabel('time $t$')\n",
    "#\n",
    "n_int = 100\n",
    "X = etas.catalog['event_date_float']\n",
    "ix_m = etas.catalog['mag']>6.1\n",
    "ix_m5 = etas.catalog['mag']>5.0\n",
    "intervals = numpy.array(X[n_int:] - X[0:-n_int] )/float(n_int)\n",
    "#\n",
    "ax1.plot(X[n_int:], intervals, ls='-', lw=3., marker='', label='intervals')\n",
    "#\n",
    "ax1.vlines(X[ix_m], min(intervals), max(intervals), color='r', lw=2.5)\n",
    "ax1.vlines(X[ix_m5], min(intervals), .5*max(intervals), color='r',  lw=2.5)\n",
    "ax2.vlines(etas.catalog['event_date_float'], etas.catalog['mag'], min(etas.catalog['mag'])-2., color='b', lw=2.)\n",
    "#ax1.set_xlim(726000)\n",
    "#\n",
    "#\n",
    "#####\n",
    "fg2 = plt.figure(figsize=(14,7))\n",
    "ax1 = fg2.add_subplot('211')\n",
    "ax2 = fg2.add_subplot('212', sharex=ax1)\n",
    "#\n",
    "ax1.grid()\n",
    "ax2.grid()\n",
    "#\n",
    "ax1.set_title('Intervals')\n",
    "ax1.set_ylabel('Mean Interval $\\Delta t / N$')\n",
    "ax2.set_title('Magnitudes')\n",
    "#\n",
    "ax2.set_xlabel('Event Count $n$ (Natural time)')\n",
    "#\n",
    "ax1.plot(numpy.arange(1, len(intervals)+1), intervals, ls='-', lw=3., marker='', label='intervals')\n",
    "#\n",
    "ax1.vlines(numpy.arange(len(etas.catalog))[ix_m], min(intervals), max(intervals), color='r', lw=2.5)\n",
    "ax2.vlines(numpy.arange(len(etas.catalog)), etas.catalog['mag'], min(etas.catalog['mag'])-2., color='b', lw=2.)\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now, let's look at that last one up close:\n",
    "#\n",
    "#####\n",
    "fg2 = plt.figure(figsize=(14,7))\n",
    "ax1 = fg2.add_subplot('211')\n",
    "ax2 = fg2.add_subplot('212', sharex=ax1)\n",
    "#\n",
    "ax1.grid()\n",
    "ax2.grid()\n",
    "#\n",
    "ax1.set_title('Intervals')\n",
    "ax1.set_ylabel('Mean Interval $\\Delta t / N$')\n",
    "ax2.set_title('Magnitudes')\n",
    "#\n",
    "ax2.set_xlabel('Event Count $n$ (Natural time)')\n",
    "#\n",
    "#\n",
    "k0 = 3300\n",
    "ax1.plot(numpy.arange(1+k0, len(intervals)+1), intervals[k0:], ls='-', lw=3., marker='', label='intervals')\n",
    "#\n",
    "ax1.vlines(numpy.arange(len(etas.catalog))[ix_m], min(intervals), max(intervals), color='r', lw=2.5)\n",
    "ax2.vlines(numpy.arange(k0, len(etas.catalog)), etas.catalog['mag'][k0:], min(etas.catalog['mag'])-2., color='b', lw=2.)\n",
    "#\n",
    "#ax1.set_ylim(-.01, .41)\n",
    "ax1.set_yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(etas.catalog.dtype.names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "mainshocks = sorted(etas.catalog[etas.catalog['event_date']>dtm.datetime(2019,6,20)],\n",
    "                    key=lambda rw:rw['mag'])[-2:]\n",
    "#\n",
    "print('** mainshocks: ', mainshocks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "ix = etas.catalog['event_date']>dtm.datetime(2019,6,20)\n",
    "\n",
    "ms2 = (etas.catalog[ix])[numpy.argsort( (etas.catalog[ix])['mag'])[-2:]]\n",
    "print('** ms2: ', ms2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "m6, m7 = mainshocks\n",
    "print('foreshock interval: ', m7['event_date_float']- m6['event_date_float'])\n",
    "#\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#\n",
    "cum_cat = mycat[mycat['event_date_float']<(mainshocks[1]['event_date_float']-1.25)]\n",
    "\n",
    "# try some cumulative experiments (we are developing another script for this elsewhere...):\n",
    "eq_prams2 = eq_prams.copy()\n",
    "eq_prams2['t_now']    = mpd.num2date(mainshocks[0]['event_date_float'])\n",
    "#eq_prams2['t_future'] = mpd.date2num(dtm.datetime.now(pytz.timezone('UTC'))) #mainshocks[1]['event_date_float']-.1\n",
    "eq_prams2['t_future'] = mainshocks[1]['event_date_float']-.1\n",
    "#\n",
    "#eq_prams2['cat_len'] = 30\n",
    "etas2 = gep.ETAS_mpp(n_cpu=n_cpu, catalog=cum_cat,\n",
    "                    **eq_prams2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "fg2=plt.figure(0, figsize=(12,10))\n",
    "ax=plt.gca()\n",
    "etas2.make_etas_contour_map(n_contours=25, fignum=0, map_resolution='f', alpha=.3, ax=ax)\n",
    "#\n",
    "#mainshock = sorted(etas.catalog, key=lambda rw: rw['mag'])[-1]\n",
    "#print('mainshock: ', mainshock)\n",
    "# get mainshock. it's an m>6 event in the last week or so... this is subjective.\n",
    "# if we just look for the biggest event, we get the L'Aquila event, so we'll need to be more creative...\n",
    "# or just specify it.\n",
    "\n",
    "mainshock = etas2.catalog[-1]\n",
    "for j,eq in enumerate(reversed(etas2.catalog)):\n",
    "    #print('*** ', pytz.utc.localize(eq['event_date'].astype(dtm.datetime)))\n",
    "    if pytz.utc.localize(eq['event_date'].astype(dtm.datetime))<etas2.t_now-dtm.timedelta(days=180): break\n",
    "    if eq['mag']>mainshock['mag']:\n",
    "        mainshock = eq\n",
    "        #\n",
    "    #\n",
    "#\n",
    "print('ms: ', mainshock, mainshock['lon'], mainshock['lat'])\n",
    "x,y = etas2.cm(mainshock['lon'], mainshock['lat'])\n",
    "#\n",
    "#print('mm: ', max(etas.catalog['mag']))\n",
    "#\n",
    "# let's get everything m>6 in the last 6 months?\n",
    "m6s = [rw for rw in etas2.catalog if rw['mag'] >= 6. \n",
    "       and pytz.utc.localize(rw['event_date'].astype(dtm.datetime))>to_dt-dtm.timedelta(days=180)]\n",
    "#\n",
    "# plot mainshock:\n",
    "dt = mainshock['event_date'].astype(dtm.datetime)\n",
    "dt=t0\n",
    "dt_str = '{}-{}-{} {}:{}:{}'.format(dt.year, dt.month, dt.day, dt.hour, dt.minute, dt.second)\n",
    "#etas.cm.plot([x], [y], latlon=False, marker='*', color='r', ms=16, zorder=11,\n",
    "#                   label='m={}, {}'.format(mainshock['mag'], dt_str))\n",
    "#etas.cm.plot([lon0], [lat0], latlon=False, marker='*', color='r', ms=16, zorder=11,\n",
    "#                   label='m={}, {}'.format(m0, dt_str))\n",
    "\n",
    "ax.set_title('ETAS: {},\\n {}-{}\\n\\n'.format(event_name, etas2.t_now, mpd.num2date(etas2.t_future)), size=16)\n",
    "# for j,m6 in enumerate(m6s):\n",
    "#     clr = colors_[j%len(colors_)]\n",
    "#     #\n",
    "#     dt = m6['event_date'].astype(dtm.datetime)\n",
    "#     dt_str = '{}-{}-{} {}:{}:{}'.format(dt.year, dt.month, dt.day, dt.hour, dt.minute, dt.second)\n",
    "#     etas.cm.scatter(m6['lon'], m6['lat'], s=2*(m6['mag']+2.), edgecolors=clr, \n",
    "#                           c='none', marker='o', zorder=11, label='m={}, {}'.format(m6['mag'], dt_str))\n",
    "\n",
    "# ix = (numpy.array([pytz.utc.localize(x.astype(dtm.datetime)) for x in etas.catalog['event_date']])<=etas.t_now and\n",
    "#       numpy.array([pytz.utc.localize(x.astype(dtm.datetime)) \n",
    "#                    for x in etas.catalog['event_date']])>=dtm.datetime(2019,7,4, tzinfo=pytz.timezone('UTC')))\n",
    "ix = numpy.array([x<=etas2.t_now and x>dtm.datetime(2019,7,4, tzinfo=pytz.timezone('UTC'))\n",
    "      for x in [pytz.utc.localize(x.astype(dtm.datetime)) for x in etas2.catalog['event_date']]])\n",
    "#\n",
    "etas2.cm.plot(etas2.catalog['lon'][ix], etas2.catalog['lat'][ix], marker='.', ls='')\n",
    "#x,y = etas.cm(*ll_sacramento)\n",
    "#etas.cm.scatter([x],[y], marker='o', s=18, edgecolors='r', c='r',\n",
    "#                    label='Sacramento')\n",
    "t_cat = mpd.date2num(etas2.t_now-dtm.timedelta(days=15))\n",
    "print('tt: ', t_cat, etas2.catalog['event_date'][0], type(etas2.catalog['event_date'][0]))\n",
    "\n",
    "#k=0\n",
    "\n",
    "# for j,rw in enumerate(etas.catalog):\n",
    "#     if mpd.date2num(rw['event_date'].astype(dtm.datetime))<t_cat: continue\n",
    "#     k+=1\n",
    "#     clr = colors_[k%len(colors_)]\n",
    "#     #\n",
    "#     dt = rw['event_date'].astype(dtm.datetime)\n",
    "#     dt_str = '{}-{}-{} {}:{}:{}'.format(dt.year, dt.month, dt.day, dt.hour, dt.minute, dt.second)\n",
    "#     #etas.cm.scatter(rw['lon'],rw['lat'], s=3*(rw['mag']+12.), edgecolors=clr, \n",
    "#     #                      c='none', marker='o', zorder=11, label='m={}, {}'.format(rw['mag'], dt_str))\n",
    "#     etas.cm.plot(rw['lon'],rw['lat'], ms=2.*(rw['mag']+2.), color=clr, \n",
    "#                           marker='o', zorder=11, label='m={}, {}'.format(rw['mag'], dt_str), latlon=True)\n",
    "    \n",
    "    #\n",
    "ax.legend(loc=0)\n",
    "#print(etas.catalog[-10:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "etas2.latses[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_ms6 = gep.Earthquake(mainshocks[0])\n",
    "q_ms7 = gep.Earthquake(mainshocks[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(etas2.catalog[-1])\n",
    "#\n",
    "# total number of events?\n",
    "# Note: this comes out low, but pushing order of magnitude...\n",
    "#\n",
    "N_est = numpy.sum(etas2.ETAS_array['z'])*etas2.d_lat*etas2.d_lon*numpy.cos(numpy.mean(etas2.latses)*deg2rad)*gep.deg2km**2.\n",
    "N_act = len(mycat[numpy.logical_and(mycat['event_date_float']>=etas2.t_forecast,\n",
    "                                    mycat['event_date_float']<=etas2.t_future)])\n",
    "#\n",
    "print('Ns: ', N_est, N_act, 10.**(q_ms7.mag - etas2.mc -1.))\n",
    "# fg = plt.figure(figsize=(10,8))\n",
    "# ax = plt.gca()\n",
    "# ax.grid()\n",
    "# #\n",
    "# ax.plot(etas2.ETAS_array['z'])\n",
    "# #ax.set_ylim(-.0001, .005 )\n",
    "# ax.set_yscale('log')\n",
    "#\n",
    "# fg = plt.figure(figsize=(8,6))\n",
    "# ax = plt.gca()\n",
    "# #\n",
    "# ax.plot(etas2.ETAS_array['z'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(etas2.catalog[-10:])\n",
    "\n",
    "print('** ', etas2.t_0)\n",
    "print('** ', etas2.t_forecast, mpd.num2date(etas2.t_forecast))\n",
    "print('** ', etas2.t_now)\n",
    "print('** ', etas2.t_future, mpd.num2date(etas2.t_future))\n",
    "\n",
    "\n",
    "#print('** ', mainshocks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for rw in mainshocks:\n",
    "    print(rw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_ms6.orate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(etas2.t_forecast, q_ms6.event_date_float, q_ms7.event_date_float)\n",
    "print(etas2.t_future)\n",
    "print(etas2.t_future-etas2.t_forecast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(q_ms6.omori_rate(t=etas2.t_forecast, t_to=None) )\n",
    "print(q_ms6.omori_rate(t=q_ms6.event_date_float+.005, t_to=q_ms6.event_date_float+1.5))\n",
    "print('** ', q_ms6.omori_rate(t=etas2.t_forecast, t_to=etas2.t_future))\n",
    "#print(q_ms6.min)\n",
    "#print(etas2.mc, etas2.mc_etas)\n",
    "#\n",
    "#print('** ', 10**(6.4-2.5-1.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(q_ms6.local_intensity(t=q_ms6.event_date_float+.005, t_to=q_ms6.event_date_float+1.5, lon=q_ms6.lon+.1, \n",
    "                            lat=q_ms6.lat+.1))\n",
    "#\n",
    "print(q_ms6.local_intensity(t=etas2.t_forecast+.1, t_to=etas2.t_future, lon=q_ms6.lon+.1, \n",
    "                            lat=q_ms6.lat+.1))\n",
    "#\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cum_cat = mycat[mycat['event_date_float']<(mainshocks[0]['event_date_float']+1)]\n",
    "Ns = numpy.array([gep.Earthquake(rw).omori_rate(etas2.t_forecast, etas2.t_future+5) for rw in etas2.catalog])\n",
    "Ns2 = numpy.array([gep.Earthquake(rw).omori_rate(etas2.t_forecast, etas.t_forecast) for rw in etas.catalog])\n",
    "#\n",
    "print('Ns: ', Ns[-10:])\n",
    "#\n",
    "fg = plt.figure(figsize=(12,8))\n",
    "ax1 = plt.subplot('211')\n",
    "ax2 = plt.subplot('212')\n",
    "#\n",
    "#ax1.plot(etas2.catalog['event_date_float'], etas2.catalog['mag'])\n",
    "ax1.plot(etas2.catalog['mag'])\n",
    "#ax2.plot(etas2.catalog['event_date_float'], Ns)\n",
    "ax2.plot(range(len(Ns)), Ns, alpha=.5)\n",
    "ax2.plot(range(len(Ns2)), Ns2, alpha=.5)\n",
    "\n",
    "\n",
    "ax2.set_yscale('log')\n",
    "ax2.grid()\n",
    "#ax2.set_xlim((3300, None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ns = numpy.array([gep.Earthquake(rw).omori_rate(etas.t_forecast-10, None) for rw in etas.catalog])\n",
    "Ns2 = numpy.array([gep.Earthquake(rw).omori_rate(etas.t_forecast, None) for rw in etas.catalog])\n",
    "#\n",
    "print('Ns: ', Ns[-10:])\n",
    "#\n",
    "fg = plt.figure(figsize=(12,8))\n",
    "ax1 = plt.subplot('211')\n",
    "ax2 = plt.subplot('212', sharex=ax1)\n",
    "\n",
    "ax1.grid()\n",
    "ax2.grid()\n",
    "#\n",
    "ax1.set_ylabel('magnitude $m$')\n",
    "\n",
    "#\n",
    "#ax1.plot(etas2.catalog['event_date_float'], etas2.catalog['mag'])\n",
    "ax1.plot(etas.catalog['mag'])\n",
    "#ax2.plot(etas2.catalog['event_date_float'], Ns)\n",
    "ax2.plot(range(len(Ns)), Ns, alpha=.5)\n",
    "ax2.plot(range(len(Ns2)), Ns2, alpha=.5)\n",
    "\n",
    "\n",
    "ax2.set_yscale('log')\n",
    "ax2.grid()\n",
    "#ax2.set_xlim((3300, None))\n",
    "\n",
    "#fg = plt.figure(figsize=(12,4))\n",
    "#ax = plt.gca()\n",
    "ax = ax2.twinx()\n",
    "#\n",
    "#ax.set_yscale('log')\n",
    "#ax.plot([gep.Earthquake(rw, t_1=etas2.t_forecast, t_2=etas2.t_future).orate for rw in mycat])\n",
    "#ax.plot([gep.Earthquake(rw, t_1=etas2.t_forecast, t_2=etas2.t_future).t_1 - mainshocks[0]['event_date_float'] for rw in mycat])\n",
    "ax.plot([etas2.t_future - gep.Earthquake(rw, t_1=mainshocks[0]['event_date_float'],\n",
    "                        t_2=etas2.t_future).t_1 for rw in mycat], ls='--')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's do one of those dist vs time plots:\n",
    "import numba\n",
    "@numba.jit\n",
    "def spherical_dist(lon_0=0., lat_0=0., lon_1=0., lat_1=0., Rearth = 6378.1):\n",
    "    #\n",
    "    #Rearth = 6378.1\t# km\n",
    "    #deg2rad=2.0*math.pi/360.\n",
    "    #\n",
    "    phif  = lat_1*deg2rad\n",
    "    lambf = lon_1*deg2rad\n",
    "    phis  = lat_0*deg2rad\n",
    "    lambs = lon_0*deg2rad\n",
    "    #\n",
    "    #\n",
    "    dphi = (phif - phis)\n",
    "    dlambda = (lambf - lambs)\n",
    "    #this one is supposed to be bulletproof:\n",
    "    #sighat3 = math.atan( math.sqrt((math.cos(phif)*math.sin(dlambda))**2.0 + (math.cos(phis)*math.sin(phif) - math.sin(phis)*math.cos(phif)*math.cos(dlambda))**2.0 ) / (math.sin(phis)*math.sin(phif) + math.cos(phis)*math.cos(phif)*math.cos(dlambda))  )\n",
    "    #R3 = Rearth * sighat3\n",
    "    #\n",
    "    #return R3\n",
    "    return Rearth*numpy.arctan( numpy.sqrt((numpy.cos(phif)*numpy.sin(dlambda))**2.0 + \n",
    "                             (numpy.cos(phis)*numpy.sin(phif) - numpy.sin(phis)*numpy.cos(phif)*numpy.cos(dlambda))**2.0 ) /\n",
    "                               (numpy.sin(phis)*numpy.sin(phif) + numpy.cos(phis)*numpy.cos(phif)*numpy.cos(dlambda))  )\n",
    "# \n",
    "#  gep.shperical_dist(lon_lat_from=[self.lon, self.lat], lon_lat_to=to_lon_lat)\n",
    "RT_6 = numpy.array([spherical_dist(mycat['lon'], mycat['lat'], q_ms6.lon, q_ms6.lat),\n",
    "                    mycat['event_date_float']-q_ms6.event_date_float]).T\n",
    "#\n",
    "RT_7 = numpy.array([spherical_dist(mycat['lon'], mycat['lat'], q_ms7.lon, q_ms7.lat),\n",
    "                    mycat['event_date_float']-q_ms7.event_date_float]).T\n",
    "\n",
    "\n",
    "\n",
    "ix = numpy.logical_and(numpy.logical_and(RT_6[:,1]>-1., RT_6[:,1]<26.), RT_6[:,0]<125.)\n",
    "fg = plt.figure(figsize=(14,8))\n",
    "ax = plt.gca()\n",
    "ax.grid()\n",
    "ax.set_xscale('log')\n",
    "ax.set_yscale('log')\n",
    "#\n",
    "ax.plot(RT_6[:,1][ix], RT_6[:,0][ix], ls='', marker='.')\n",
    "\n",
    "ix = numpy.logical_and(numpy.logical_and(RT_7[:,1]>-5., RT_7[:,1]<26.), RT_7[:,0]<125.)\n",
    "#ix = numpy.array([True for _ in RT_7])\n",
    "fg = plt.figure(figsize=(14,8))\n",
    "ax = plt.gca()\n",
    "ax.grid()\n",
    "ax.set_xscale('log')\n",
    "ax.set_yscale('log')\n",
    "#\n",
    "ax.plot(RT_7[:,1][ix], RT_7[:,0][ix], ls='', marker='.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(q_ms6.lon, q_ms6.lat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
